{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Keys\n",
    "\n",
    "Export NVIDIA API keys for authentication\n",
    "Get your API keys from: https://build.nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Services\n",
    "\n",
    "Start all required services for CA-RAG:\n",
    "1. Export your NVIDIA API key:\n",
    "   ```\n",
    "   export NVIDIA_API_KEY=xxxx\n",
    "   ```\n",
    "\n",
    "2. Start the services using docker-compose:\n",
    "   ```\n",
    "   make -C docker start_compose\n",
    "   ```\n",
    "\n",
    "This will start the ingestion service (default port 8001) and retrieval service (default port 8000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env NVIDIA_BUILD_API_KEY=xxxx\n",
    "%env NVIDIA_API_KEY=xxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install NV-Ingest\n",
    "\n",
    "Install NV-Ingest following the steps [here](https://github.com/NVIDIA/nv-ingest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start NV-Ingest Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the nv-ingest client to process the pdf documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nv_ingest.util.pipeline.pipeline_runners import start_pipeline_subprocess, PipelineCreationSchema\n",
    "from nv_ingest_client.client import Ingestor, NvIngestClient\n",
    "from nv_ingest_client.message_clients.simple.simple_client import SimpleClient\n",
    "\n",
    "# Initialize pipeline config and start subprocess\n",
    "config = PipelineCreationSchema()\n",
    "pipeline_process = start_pipeline_subprocess(config)\n",
    "\n",
    "# Initialize NV-Ingest client\n",
    "client = NvIngestClient(\n",
    "    message_client_allocator=SimpleClient,\n",
    "    message_client_port=7671,\n",
    "    message_client_hostname=\"localhost\"\n",
    ")\n",
    "\n",
    "# Milvus configuration\n",
    "milvus_uri = \"milvus.db\"  # Using milvus-lite since gpu_cagra indexing not yet available\n",
    "collection_name = \"test\"\n",
    "sparse = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text, tables\n",
    "# Note: Images are not supported in the current version\n",
    "ingestor = (\n",
    "    Ingestor(client=client)\n",
    "    .files(\"data/multimodal_test.pdf\")\n",
    "    .extract(\n",
    "        extract_text=True,\n",
    "        extract_tables=True,\n",
    "        extract_charts=True,\n",
    "        extract_images=False,\n",
    "        paddle_output_format=\"markdown\",\n",
    "        extract_infographics=True,\n",
    "        # Slower, but maximally accurate, especially for PDFs with pages that are scanned image\u001bP1+r4632=1B5B32347E\u001b\\\u001bP0+r\u001b\\\u001bP0+r\u001b\\\u001bP1+r6B62=7F\u001b\\\u001bP0+r\u001b\\\u001bP1+r6B44=1B5B337E\u001b\\\u001bP1+r6B68=1B4F48\u001b\\\u001bP1+r4037=1B4F46\u001b\\\u001bP1+r6B50=1B5B357E\u001b\\\u001bP1+r6B4E=1B5B367E\u001b\\s\n",
    "        # extract_method=\"nemoretriever_parse\",\n",
    "        text_depth=\"page\"\n",
    "    )\n",
    ")\n",
    "\n",
    "results = ingestor.ingest(show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the documents in Context Aware RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Documents to Context-Aware RAG\n",
    "\n",
    "This section demonstrates how to add documents to CA-RAG using POST requests to the ingestion service. We'll upload the previously extracted text, tables and charts for data ingestion. Once ingestion is complete, the documents will be available for question-answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload text results to server\n",
    "import requests\n",
    "import json\n",
    "\n",
    "ingestion_url = <URL>:<PORT> # default is localhost:8001\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Initialize service\n",
    "init_data = {\"config_path\": \"/app/config/config.yaml\", \"uuid\": \"1\"}\n",
    "response = requests.post(\n",
    "    f\"{ingestion_url}/init\", headers=headers, data=json.dumps(init_data)\n",
    ")\n",
    "\n",
    "# Extract text documents from results\n",
    "add_doc_data_list = []\n",
    "doc_index = 0\n",
    "for _, doc in enumerate(results[0]):\n",
    "    if doc[\"document_type\"] == \"text\":\n",
    "        doc_data = {\n",
    "            \"document\": doc[\"metadata\"][\"content\"],\n",
    "            \"doc_index\": doc_index\n",
    "        }\n",
    "        \n",
    "        # Add metadata for first/last docs\n",
    "        if doc_index == 0:\n",
    "            doc_data[\"doc_metadata\"] = {\"is_first\": True}\n",
    "            \n",
    "        add_doc_data_list.append(doc_data)\n",
    "        doc_index += 1\n",
    "\n",
    "# Upload documents\n",
    "for add_doc_data in add_doc_data_list:\n",
    "    response = requests.post(\n",
    "        f\"{ingestion_url}/add_doc\", headers=headers, data=json.dumps(add_doc_data)\n",
    "    )\n",
    "    print(f\"Added document {add_doc_data['doc_index']}\")\n",
    "\n",
    "# Add the terminating document\n",
    "doc_data = {\n",
    "            \"document\": \".\",\n",
    "            \"doc_index\": doc_index,\n",
    "            \"doc_metadata\": {\"is_last\": True}\n",
    "        }\n",
    "response = requests.post(\n",
    "    f\"{ingestion_url}/add_doc\", headers=headers, data=json.dumps(doc_data)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Service\n",
    "In this section, we initialize the retrieval service with the same UUID used for data ingestion. We then send a request to summarize the document using the retrieval service's API endpoints. The service processes the question and returns a summary based on the previously ingested documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_url = <URL>:<PORT> # default is localhost:8000\n",
    "\n",
    "# Initialize service with same uuid as data ingestion\n",
    "init_data = {\"config_path\": \"/app/config/config.yaml\", \"uuid\": \"1\"}\n",
    "response = requests.post(\n",
    "    f\"{retrieval_url}/init\", headers=headers, data=json.dumps(init_data)\n",
    ")\n",
    "\n",
    "# Send retrieval request\n",
    "call_data = {\"chat\": {\"question\": \"Summarize the document.\"}}\n",
    "request_data = {\"state\": call_data}\n",
    "response = requests.post(\n",
    "    f\"{retrieval_url}/call\", headers=headers, data=json.dumps(request_data)\n",
    ")\n",
    "print(response.json()[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "via310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
